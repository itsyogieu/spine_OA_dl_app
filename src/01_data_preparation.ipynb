{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation for Spine Degeneration Classification\n",
    "\n",
    "This notebook prepares spine X-ray images for deep learning model training.\n",
    "\n",
    "## Steps:\n",
    "1. Load and explore the dataset\n",
    "2. Visualize class distribution\n",
    "3. Set up data augmentation\n",
    "4. Create data generators\n",
    "5. Calculate class weights for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "DATASET_DIR = Path('../dataset')\n",
    "TRAIN_DIR = DATASET_DIR / 'train'\n",
    "VAL_DIR = DATASET_DIR / 'val'\n",
    "TEST_DIR = DATASET_DIR / 'test'\n",
    "\n",
    "# Image parameters\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['grade_0', 'grade_1', 'grade_2', 'grade_3', 'grade_4']\n",
    "CLASS_LABELS = ['Healthy', 'Doubtful', 'Minimal', 'Moderate', 'Severe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(directory):\n",
    "    \"\"\"Count images in each class folder\"\"\"\n",
    "    counts = {}\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_dir = directory / class_name\n",
    "        if class_dir.exists():\n",
    "            counts[class_name] = len(list(class_dir.glob('*.*')))\n",
    "        else:\n",
    "            counts[class_name] = 0\n",
    "    return counts\n",
    "\n",
    "# Count images in each split\n",
    "train_counts = count_images(TRAIN_DIR)\n",
    "val_counts = count_images(VAL_DIR)\n",
    "test_counts = count_images(TEST_DIR)\n",
    "\n",
    "print(\"Dataset Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "df = pd.DataFrame({\n",
    "    'Class': CLASS_LABELS,\n",
    "    'Train': list(train_counts.values()),\n",
    "    'Validation': list(val_counts.values()),\n",
    "    'Test': list(test_counts.values())\n",
    "})\n",
    "df['Total'] = df['Train'] + df['Validation'] + df['Test']\n",
    "print(df)\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total images: {df['Total'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Bar chart\n",
    "df_plot = df.set_index('Class')[['Train', 'Validation', 'Test']]\n",
    "df_plot.plot(kind='bar', ax=axes[0], color=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Image Distribution by Split', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Severity Grade', fontsize=12)\n",
    "axes[0].set_ylabel('Number of Images', fontsize=12)\n",
    "axes[0].legend(title='Split')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "plt.setp(axes[0].xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Pie chart\n",
    "total_per_class = df.groupby('Class')['Total'].sum()\n",
    "colors = ['#2ecc71', '#f39c12', '#3498db', '#e74c3c', '#9b59b6']\n",
    "axes[1].pie(total_per_class, labels=CLASS_LABELS, autopct='%1.1f%%', \n",
    "           colors=colors, startangle=90)\n",
    "axes[1].set_title('Overall Class Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../assets/data.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Class Weights\n",
    "\n",
    "Since the dataset may be imbalanced, we calculate class weights to give more importance to underrepresented classes during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "train_samples = np.array(list(train_counts.values()))\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(len(CLASS_NAMES)),\n",
    "    y=np.repeat(np.arange(len(CLASS_NAMES)), train_samples)\n",
    ")\n",
    "\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class Weights:\")\n",
    "for i, (class_name, weight) in enumerate(zip(CLASS_LABELS, class_weights)):\n",
    "    print(f\"  {class_name:12s}: {weight:.3f}\")\n",
    "    \n",
    "# Save class weights for later use\n",
    "np.save('../src/class_weights.npy', class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation and test generators (no augmentation)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of images\n",
    "sample_batch = next(train_generator)\n",
    "sample_images = sample_batch[0]\n",
    "sample_labels = sample_batch[1]\n",
    "\n",
    "# Plot some augmented images\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(8):\n",
    "    axes[i].imshow(sample_images[i])\n",
    "    label_idx = np.argmax(sample_labels[i])\n",
    "    axes[i].set_title(f'Grade {label_idx}: {CLASS_LABELS[label_idx]}', fontsize=11)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Sample Augmented Training Images', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "✅ Dataset loaded and explored\n",
    "✅ Class distribution visualized\n",
    "✅ Class weights calculated for imbalanced data\n",
    "✅ Data augmentation configured\n",
    "✅ Data generators created\n",
    "\n",
    "**Next Steps:**\n",
    "- Train models using notebooks: `02_model_xception.ipynb`, `02_model_resnet50.ipynb`, `02_model_inception_resnet_v2.ipynb`\n",
    "- Create ensemble model: `02_ensemble_models.ipynb`\n",
    "- Evaluate on test set: `03_best_model_on_test.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA PREPARATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total training images: {train_generator.samples}\")\n",
    "print(f\"Total validation images: {val_generator.samples}\")\n",
    "print(f\"Total test images: {test_generator.samples}\")\n",
    "print(f\"Number of classes: {len(CLASS_NAMES)}\")\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
